import os
import base64
import re
import pickle
import time
from bs4 import BeautifulSoup
from googleapiclient.discovery import build
from google.auth.transport.requests import Request
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow

SCOPES = ['https://www.googleapis.com/auth/gmail.readonly']

def authenticate_gmail():
    """è®¤è¯GmailæœåŠ¡"""
    creds = None
    token_file = f'token.pickle'
    credentials_file = f'credentials.json'
    
    if os.path.exists(token_file):
        with open(token_file, 'rb') as token:
            creds = pickle.load(token)
    
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            flow = InstalledAppFlow.from_client_secrets_file(credentials_file, SCOPES)
            creds = flow.run_local_server(port=0)
        with open(token_file, 'wb') as token:
            pickle.dump(creds, token)
    return build('gmail', 'v1', credentials=creds)

def search_emails(service, target_email, max_results=10):
    """æœç´¢ç›®æ ‡é‚®ä»¶"""
    messages = []
    for label in ['INBOX', 'CATEGORY_SOCIAL']:
        result = service.users().messages().list(
            userId='me',
            labelIds=[label],
            maxResults=max_results,
            q=f'to:{target_email} from:no-reply@mail.instagram.com'
        ).execute()
        messages.extend(result.get('messages', []))
    return messages[:max_results]

def extract_html_content(payload):
    """æå–é‚®ä»¶HTMLå†…å®¹"""
    if payload['mimeType'] == 'text/html':
        data = payload['body'].get('data', '')
        if data:
            return base64.urlsafe_b64decode(data).decode('utf-8')
    elif 'parts' in payload:
        for part in payload['parts']:
            content = extract_html_content(part)
            if content:
                return content
    return ''

def parse_verification_code(html):
    """è§£æéªŒè¯ç """
    try:
        soup = BeautifulSoup(html, 'html.parser')
        # åŒ¹é…åŒ…å«éªŒè¯ç çš„HTMLå…ƒç´ 
        code_element = soup.find('td', style=re.compile(r'font-size:\s*32px'))
        if code_element and code_element.text.strip().isdigit():
            return code_element.text.strip()
        return None
    except Exception as e:
        #print(f"âŒ HTMLè§£æå¤±è´¥: {e}")
        return None

def fetch_verification_code(service, target_email, retries=3, delay=5):
    """è·å–éªŒè¯ç ä¸»é€»è¾‘"""
    for attempt in range(1, retries+1):
        #print(f"\nğŸ”„ å°è¯•ç¬¬ {attempt} æ¬¡è·å–ï¼ˆå…± {retries} æ¬¡ï¼‰")
        messages = search_emails(service, target_email)
        
        if not messages:
            #print("âš ï¸ æœªæ‰¾åˆ°ç›®æ ‡é‚®ä»¶")
            time.sleep(delay)
            continue
            
        #print(f"ğŸ“¨ æ‰¾åˆ° {len(messages)} å°ç›¸å…³é‚®ä»¶")
        
        for i, msg in enumerate(messages):
            full_msg = service.users().messages().get(
                userId='me',
                id=msg['id'],
                format='full'
            ).execute()
            
            # æå–é‚®ä»¶å†…å®¹
            html_content = extract_html_content(full_msg['payload'])
            if not html_content:
                continue
                
            # è§£æéªŒè¯ç 
            if code := parse_verification_code(html_content):
                #print(f"âœ… åœ¨ç¬¬ {i+1} å°é‚®ä»¶ä¸­å‘ç°éªŒè¯ç ")
                return code
                
        #print(f"â³ ç­‰å¾… {delay} ç§’åé‡è¯•...")
        time.sleep(delay)
        
    return None